{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import bz2\n",
    "import os\n",
    "import urllib\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "import xml.etree.ElementTree as ET\n",
    "from xml import etree\n",
    "import pandas as pd\n",
    "import json\n",
    "from collections import Counter\n",
    "import re\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Something Some Thing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Requirments:\n",
    "- Python 3.6\n",
    "- Jupyter Notebooks (do-oh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Download and parse the wikipedia data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Data\n",
    "data_url = \"https://dumps.wikimedia.org/nowiki/latest/nowiki-latest-pages-articles-multistream.xml.bz2\"\n",
    "data_dirpath = Path.cwd() / \"data\"\n",
    "data_extracted_dirpath = data_dirpath / \"extracted\"\n",
    "data_filepath = data_dirpath / \"nowiki-latest-pages-articles-multistream.xml.bz2\"\n",
    "\n",
    "#WikiExtractor\n",
    "wikiextractor_github_url = \"https://github.com/attardi/wikiextractor\"\n",
    "wikiextractor_dirpath = Path.cwd() / \"wikiextractor\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 498 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if not os.path.exists(data_filepath):\n",
    "    print(f\"Data file '{data_filepath}' not found. Downloading data.\")\n",
    "    if not os.path.exists(data_dirpath):\n",
    "        os.makedirs(data_dirpath)\n",
    "    urllib.request.urlretrieve (data_url, data_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Extract and parse data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(data_extracted_dirpath):\n",
    "    if not os.path.exists(wikiextractor_dirpath):\n",
    "        print(f\"WikiExtractor not found. Cloining WikiExtractor from '{wikiextractor_github_url}'\")\n",
    "        subprocess.Popen(\"git clone {wikiextractor_github_url} {wikiextractor_dirpath}\")\n",
    "    print(f\"Extracting wikipedia articles to '{data_extracted_dirpath}'\")\n",
    "    subprocess.Popen(f\"python {wikiextractor_dirpath}/WikiExtractor.py -o {data_extracted_dirpath} --json {compressed_data_filepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Load data as a pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def data_filepath_gen():\n",
    "    for subdir_name, subdir_list, file_list in os.walk(data_extracted_dirpath):\n",
    "        for file_name in file_list:\n",
    "            yield data_extracted_dirpath / subdir_name / file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def json2df(json_filepath):\n",
    "    with open(json_filepath, encoding='utf8') as f:\n",
    "        json_data = [json.loads(line) for line in f]\n",
    "        df = pd.DataFrame(json_data)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def read_wiki_data(max_articles=None):\n",
    "    num_articles = 0\n",
    "    all_dfs = []\n",
    "    \n",
    "    for filepath in data_filepath_gen():\n",
    "        sub_df = json2df(filepath)\n",
    "        all_dfs.append(sub_df)\n",
    "        num_articles += sub_df.shape[0]\n",
    "        if max_articles is not None and num_articles >= max_articles:\n",
    "            break\n",
    "            \n",
    "    df = pd.concat(all_dfs, axis=0)\n",
    "    df.set_index(\"id\", inplace=True)\n",
    "    if max_articles is not None:\n",
    "        return df.iloc[:max_articles]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Read wordcounts directly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "RE_WORD = re.compile(\"[^\\W\\d_]+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def json2wordcounts(json_filepath):\n",
    "    with open(json_filepath, encoding='utf8') as f:\n",
    "        word_counts = Counter()\n",
    "        for line in f:\n",
    "            text = json.loads(line).get(\"text\")\n",
    "            if text is None:\n",
    "                continue\n",
    "            word_counts.update(Counter(RE_WORD.findall(text.lower())))\n",
    "        return word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def get_wiki_wordcounts():\n",
    "    word_counts = Counter()\n",
    "    for filepath in data_filepath_gen():\n",
    "        word_counts.update(json2wordcounts(filepath))\n",
    "    return word_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Get the wordcounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed word counts for wikipedia articles (83.89 MB)\n",
      "1.652e+06 unique words found\n",
      "Wall time: 2min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "wiki_word_counts = get_wiki_wordcounts()\n",
    "print(f\"Computed word counts for wikipedia articles ({sys.getsizeof(wiki_word_counts) / 1000000:.2f} MB)\")\n",
    "print(f\"{len(wiki_word_counts):.3e} unique words found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Something Some Thing\n",
    "\n",
    "Compound Words + NLP != <3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What is Natural Language Processing (NLP)?\n",
    "\n",
    "Wikipedia defines NLP as:\n",
    "<font color=\"gray\">_Natural language processing (NLP) is a field of computer science, artificial intelligence and computational linguistics concerned with the interactions between computers and human (natural) languages, and, in particular, concerned with programming computers to fruitfully process large natural language corpora._</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Statistical NLP\n",
    "\n",
    "- In the early days NLP typically involved hand coding of rules\n",
    "- Now NLP relies heavily on **Machine Learning** to _statistically_ infer rules from a large collection of text examples (e.g. documents) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## What are some use cases of NLP?\n",
    "\n",
    "- Text Categorization\n",
    "- Information Retrieval\n",
    "- Named Entity Recognition\n",
    "- Intent Recognition\n",
    "- Part-of-Speech Tagging\n",
    "- Sentiment Analysis\n",
    "\n",
    "And many other tasks which include extracting information from text, or classifying text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## How can Machine Learning be used for NLP?\n",
    "\n",
    "- All Machine Learning algorithms try to map a set of _features_ to some _target_\n",
    "- Each training example given to the ML algortihm must be a _collection of the specified features_\n",
    "- In NLP the examples are _texts_ -> **we need some way of generating features from text**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Words as Features\n",
    "\n",
    "- One common approach is to treat the **words** of the text as the features\n",
    "- The words of a text are all coherent sequences of (alphanumeric) characters, separated by _spaces_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['These', 'are', 'five', 'different', 'words']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_pattern = \"[A-Za-z]+\"\n",
    "text = \"These are five different words\"\n",
    "all_words = re.findall(word_pattern, text)\n",
    "all_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Bag-of-words\n",
    "\n",
    "- All ML algorithms expect the examples to be _collections of numbers_ of _equal length_\n",
    "- -> A list of words is not a valid representation of a text\n",
    "- One algorithm used to transform a text into a collection of numbers is called **bag-of-words**\n",
    "- _Bag-of-words_ maps all unique words into separate columns in your data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## BOW example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>is</th>\n",
       "      <th>other</th>\n",
       "      <th>some</th>\n",
       "      <th>text</th>\n",
       "      <th>this</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   and  is  other  some  text  this\n",
       "0    0   1      0     1     1     1\n",
       "1    1   1      1     1     1     1\n",
       "2    0   0      0     0     4     0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = [\n",
    "    \"This is some text\",\n",
    "    \"And this is some other text\",\n",
    "    \"Text text text text\"\n",
    "]\n",
    "\n",
    "vec = CountVectorizer()\n",
    "bow = vec.fit_transform(texts)\n",
    "\n",
    "pd.DataFrame(bow.todense(), columns=vec.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Why is Compound Words + NLP a bad match?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## What are compound words?\n",
    "\n",
    "- Compound words are words that consist of more than one stem. \n",
    "- One example is the word \"særskrivingsfeil\" which consists of the stems \"særskriving\" and \"feil\"\n",
    "- In Scandinavian languages compound words are very common"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- In English they are very rare\n",
    "- A lot of traditional NLP techniques were designed for english..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Why do they cause trouble in NLP?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>for</th>\n",
       "      <th>har</th>\n",
       "      <th>jeg</th>\n",
       "      <th>regning</th>\n",
       "      <th>reise</th>\n",
       "      <th>reiseregning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   en  for  har  jeg  regning  reise  reiseregning\n",
       "0   1    0    1    1        0      0             1\n",
       "1   2    1    1    1        1      1             0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = [\n",
    "    \"Jeg har en reiseregning\",\n",
    "    \"Jeg har en regning for en reise\"\n",
    "]\n",
    "\n",
    "vec = CountVectorizer()\n",
    "bow = vec.fit_transform(texts)\n",
    "\n",
    "pd.DataFrame(bow.todense(), columns=vec.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Text similarity (cosine similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5714285714285714"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow[0].dot(bow[1].T)[0,0] / bow.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### And when removing stopwords ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>regning</th>\n",
       "      <th>reise</th>\n",
       "      <th>reiseregning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   regning  reise  reiseregning\n",
       "0        0      0             1\n",
       "1        1      1             0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords = [\"jeg\", \"har\", \"en\", \"for\"]\n",
    "\n",
    "vec = CountVectorizer(stop_words=stopwords)\n",
    "bow = vec.fit_transform(texts)\n",
    "\n",
    "pd.DataFrame(bow.todense(), columns=vec.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Text similarity (cosine distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow[0].dot(bow[1].T)[0,0] / bow.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Aka not good ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Compound words => Many, very rare features + subword-information is lost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What if we could create some mapping between compounds and the stems they are created from?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Jeg har en reise regning', 'Jeg har en regning for en reise']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping = {\n",
    "    \"reiseregning\": \"reise regning\"\n",
    "}\n",
    "\n",
    "clean_text = lambda text: \" \".join([mapping.get(x, x) for x in text.split()])\n",
    " \n",
    "texts2 = [clean_text(text) for text in texts]\n",
    "texts2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>regning</th>\n",
       "      <th>reise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   regning  reise\n",
       "0        1      1\n",
       "1        1      1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = CountVectorizer(stop_words=stopwords)\n",
    "bow = vec.fit_transform(texts2)\n",
    "\n",
    "pd.DataFrame(bow.todense(), columns=vec.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Text similarity (cosine distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow[0].dot(bow[1].T)[0,0] / bow.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Much better!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# How can we find this mapping?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Option 1: Manually define all valid word stems, or find a dictionary of stems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src=\"https://memegenerator.net/img/instances/60127190.jpg\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Option 2: Automatically find a list of words from your own corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src=\"https://media1.tenor.com/images/b5b525642d31fc32571618da55f973e5/tenor.gif?itemid=4786736\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Algorithm for automatic compound word splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Algorithm for automatic compound word splitting\n",
    "\n",
    "1. Extract all valid words from your corpora, and their counts\n",
    "2. Discard any words that are _too rare_ or _too common_ (stopwords)\n",
    "3. For all words of length >= n:\n",
    "    - consider all possible splits of the word\n",
    "    - choose the most probable split, or no split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Step 1: Finding all valid words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akershus\n",
      "\n",
      "Akershus (fra norrønt \"akr\", åker, og \"hús\", borg eller kastell) er et norsk fylke, som grenser mot Hedmark i øst, Oppland i nord, Buskerud i vest, Østfold i sør og Oslo. Dessuten har Akershus (i kommunen Aurskog-Høland) en liten bit av riksgrensen mot Sverige i øst.\n",
      "\n",
      "Akershus er delt i tre regioner: Romerike, Follo og Vestområdet,\n",
      "hvorav sistnevnte med kommunene Asker og Bærum ligger vest for Oslofjorden og sydvest for Oslo. Øst for Oslofjorden ligger Follo, mens Romerike ligger øst o ...\n"
     ]
    }
   ],
   "source": [
    "article = read_wiki_data(1).iloc[0]\n",
    "print(f\"{article.text[:500]} ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "RE_WORD = re.compile(\"[^\\W\\d_]+\")\n",
    "article_word_counts = Counter(RE_WORD.findall(article.text.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('og', 60), ('i', 60), ('akershus', 39), ('er', 39), ('oslo', 19)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_word_counts.most_common(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## If we repeat this for all norwegian wikipedia articles..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('i', 3953876),\n",
       " ('og', 2879012),\n",
       " ('av', 1715924),\n",
       " ('som', 1552470),\n",
       " ('en', 1496552),\n",
       " ('er', 1409112),\n",
       " ('til', 1257523),\n",
       " ('på', 1169964),\n",
       " ('ble', 998262),\n",
       " ('den', 983530)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_word_counts.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Word count histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZoAAAD8CAYAAABO3GKQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZkU5aMzMrCgHjZmZFfX/AVDGIuHEls42AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1eb00fc0160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(wiki_word_counts.values())\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Many very rare features ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Total number of unique words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.65e+06 words\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(wiki_word_counts):.2e} words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of words used at most _n_ times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.41e+05 words\n"
     ]
    }
   ],
   "source": [
    "n = 1\n",
    "print(f\"{len([w for w, c in wiki_word_counts.items() if c <= n]):.2e} words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Step 2: Discard words that are too common or too rare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Drop words that are too common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['og', 'i', 'jeg', 'det', 'at', 'en', 'et', 'den', 'til', 'er']"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words(\"norwegian\")[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "wiki_word_counts2 = wiki_word_counts.copy()\n",
    "for sw in stopwords.words(\"norwegian\"):\n",
    "    if sw not in wiki_word_counts2:\n",
    "        continue\n",
    "    wiki_word_counts2.pop(sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('under', 250723), ('andre', 180805), ('første', 172290)]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_word_counts2.most_common(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Drop words that are too rare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "min_word_count = 3\n",
    "wiki_word_counts2 = {w: c for w, c in wiki_word_counts2.items() if c >= min_word_count}\n",
    "wiki_word_counts2 = Counter(wiki_word_counts2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Number of words left:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.68e+05 words\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(wiki_word_counts2):.2e} words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Select only words consiting of at least 3 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "min_word_length = 3\n",
    "wiki_word_counts2 = {w: c for w, c in wiki_word_counts2.items() if len(w) >= min_word_length}\n",
    "wiki_word_counts2 = Counter(wiki_word_counts2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Number of words left:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.65e+05 words\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(wiki_word_counts2):.2e} words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# We now how a pretty good dictionary!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Step 3: Find the most probable split of a word\n",
    "\n",
    "Key ideas: \n",
    "- All words after the split must be valid words\n",
    "- The split resulting in the _highest total word count_ for the subwords, is the most probable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Example: Reise + Regning > Reiseregning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7234"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_word_counts2[\"reise\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "369"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_word_counts2[\"regning\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_word_counts2[\"reiseregning\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_word_counts2[\"reise\"] + wiki_word_counts2[\"regning\"] > wiki_word_counts2[\"reiseregning\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Defining the split cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "INF = 1e9\n",
    "\n",
    "def split_value(*subwords):\n",
    "    return sum(wiki_word_counts2.get(sw, -INF) for sw in subwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7603"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_value(\"reise\", \"regning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1000000000.0"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_value(\"reiseregning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Problem: very common words dominating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "A word appearing 100,000 is probably not 100 times more probable than a word appearing 1000 times. A word appearing 1000 times is still a very common word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Solution: use the _log_ of the word count instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def word_value(word):\n",
    "    if word in wiki_word_counts2:\n",
    "        return log(wiki_word_counts2[word])\n",
    "    return -INF\n",
    "\n",
    "def split_value2(*subwords):\n",
    "    return sum(word_value(subword) for subword in subwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.79734405655257"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_value2(\"reise\", \"regning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1000000000.0"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_value2(\"reiseregning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## How does the _log_ function look?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAD8CAYAAABzTgP2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nfw2Dxu05/C+5AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1eb14aade80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(0.0001, 10000)\n",
    "y = np.log(x)\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000/100 = 1000.0\n",
      "log(100000) / log(100) = 2.5\n"
     ]
    }
   ],
   "source": [
    "print(f\"100000/100 = {100000/100}\")\n",
    "print(f\"log(100000) / log(100) = {log(100000) / log(100)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Case: To split or not to split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "If the word \"reiseregning\" appears 2000 times in your corpora, and the words \"reise\" and \"regning\" appear 500 times each - should we stil split it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.429216196844383"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log(500) + log(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.600902459542082"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log(2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "According to the cost function we defined we should split this word, but intuition tells us we should not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Split penalty: To prevent \"over-eager\" splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Let's say we add a plit penalty of e.g. 5 to the split value. Then:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT_PENALTY = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log(500) + log(500) - SPLIT_PENALTY < log(2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## How do we find all possible splits and select the best one?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Solution: Iterate over all possible solutions and select the best one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rei seregning\n",
      "reis eregning\n",
      "reise regning\n",
      "reiser egning\n",
      "reisere gning\n",
      "reisereg ning\n",
      "reiseregn ing\n"
     ]
    }
   ],
   "source": [
    "word = \"reiseregning\"\n",
    "for i in range(min_word_length, len(word)-min_word_length+1):\n",
    "    print(word[:i], word[i:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def find_best_split(word):\n",
    "    # No split\n",
    "    max_value, best_split= word_value(word), word\n",
    "    \n",
    "    # Consider all splits\n",
    "    for i in range(min_word_length, len(word)-min_word_length+1):\n",
    "        sw1, sw2 = word[:i], word[i:]\n",
    "        value = split_value2(sw1, sw2) - SPLIT_PENALTY\n",
    "        if value > max_value:\n",
    "            max_value, best_split = value, sw1 + \" \" + sw2\n",
    "    \n",
    "    return best_split, max_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('reise regning', 9.79734405655257)"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_best_split(\"reiseregning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('bruker konto', 9.946822988014759)"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_best_split(\"brukerkonto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Corner case 1: Words with glue-letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('særskrivingsfeil', 1.791759469228055)"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_best_split(\"særskrivingsfeil\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1000000000.0"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_value(\"særskrivings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.044522437723423"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_value(\"særskriving\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Corner case 1: Solution - consider \"remvoving\" glue letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLUE_LETTERS = \"s\"\n",
    "EDIT_PENALTY = 1\n",
    "\n",
    "def find_best_split2(word):\n",
    "    # No split\n",
    "    max_value, best_split= word_value(word), word\n",
    "    \n",
    "    # Consider all splits\n",
    "    for i in range(min_word_length, len(word)-min_word_length+1):\n",
    "        sw1, sw2 = word[:i], word[i:]\n",
    "        value = split_value2(sw1, sw2) - SPLIT_PENALTY\n",
    "        if value > max_value:\n",
    "            max_value, best_split = value, sw1 + \" \" + sw2\n",
    "            \n",
    "        if word[i] in GLUE_LETTERS:\n",
    "            sw2 = word[i+1:]\n",
    "            value = split_value2(sw1, sw2) - SPLIT_PENALTY - EDIT_PENALTY\n",
    "            if value > max_value:\n",
    "                max_value, best_split = value, sw1 + \" \" + sw2\n",
    "    \n",
    "    return best_split, max_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Now, let's try to split \"særskrivingsfeil\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('særskriving feil', 5.468064073058205)"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_best_split2(\"særskrivingsfeil\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Corner case 2: Words ending on double consonants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('internet tilgang', 9.67788898990056)"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_best_split2(\"internettilgang\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correct split should be \"internett\" + \"tilgang\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Corner case 2: Solution - consider \"adding\" another consonant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_split3(word):\n",
    "    # No split\n",
    "    max_value, best_split= word_value(word), word\n",
    "    \n",
    "    # Consider all splits\n",
    "    for i in range(min_word_length, len(word)-min_word_length+1):\n",
    "        sw1, sw2 = word[:i], word[i:]\n",
    "        value = split_value2(sw1, sw2) - SPLIT_PENALTY\n",
    "        if value > max_value:\n",
    "            max_value, best_split = value, sw1 + \" \" + sw2\n",
    "            \n",
    "        if word[i] in GLUE_LETTERS:\n",
    "            sw2 = word[i+1:]\n",
    "            value = split_value2(sw1, sw2) - SPLIT_PENALTY - EDIT_PENALTY\n",
    "            if value > max_value:\n",
    "                max_value, best_split = value, sw1 + \" \" + sw2\n",
    "                \n",
    "        if word[i-1] in 'bcdfghjklmnpqrstvxz' and word[i-1] == word[i-2]:\n",
    "            sw2 = word[i-1:]\n",
    "            value = split_value2(sw1, sw2) - SPLIT_PENALTY - EDIT_PENALTY\n",
    "            if value > max_value:\n",
    "                max_value, best_split = value, sw1 + \" \" + sw2\n",
    "    \n",
    "    return best_split, max_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Now, let's try to split \"internettilgang\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('internett tilgang', 10.246441195285314)"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_best_split3(\"internettilgang\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Some code clean-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_split4(word):\n",
    "    # No split\n",
    "    max_value, best_split= word_value(word), word\n",
    "    \n",
    "    # Consider all splits\n",
    "    for i in range(min_word_length, len(word)-min_word_length+1):\n",
    "        sw1 = word[:i]\n",
    "        sw1_value = word_value(sw1)\n",
    "        \n",
    "        split_options = [i]\n",
    "        if word[i] in GLUE_LETTERS:\n",
    "            split_options.append(i+1)\n",
    "        if word[i-1] in 'bcdfghjklmnpqrstvxz' and word[i-1] == word[i-2]:\n",
    "            split_options.append(i-1)\n",
    "            \n",
    "        for j in split_options:\n",
    "            sw2 = word[j:]\n",
    "            value = sw1_value + word_value(sw2) - SPLIT_PENALTY - (j!=i) * EDIT_PENALTY\n",
    "            if value > max_value:\n",
    "                max_value, best_split = value, sw1 + \" \" + sw2\n",
    "    \n",
    "    return best_split, max_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Corner case 3: Words consisting of more than 2 subwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('førstegangs intervju', 5.6677919274124005)"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_best_split4(\"førstegangsintervju\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('første gangs', 12.087372303918887)"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_best_split4(\"førstegangs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "=> Words will not be split consistently. Not good ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Corner case 3: Solution - run the function recursively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_split5(word):\n",
    "    # No split\n",
    "    max_value, best_split= word_value(word), word\n",
    "    \n",
    "    # Consider all splits\n",
    "    for i in range(min_word_length, len(word)-min_word_length+1):\n",
    "        sw1 = word[:i]\n",
    "        sw1_value = word_value(sw1)\n",
    "        \n",
    "        split_options = [i]\n",
    "        if word[i] in GLUE_LETTERS:\n",
    "            split_options.append(i+1)\n",
    "        if word[i-1] in 'bcdfghjklmnpqrstvxz' and word[i-1] == word[i-2]:\n",
    "            split_options.append(i-1)\n",
    "            \n",
    "        for j in split_options:\n",
    "            sw2, sw2_value = find_best_split5(word[j:])\n",
    "            value = sw1_value + sw2_value - SPLIT_PENALTY - (j!=i) * EDIT_PENALTY\n",
    "            if value > max_value:\n",
    "                max_value, best_split = value, sw1 + \" \" + sw2\n",
    "    \n",
    "    return best_split, max_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Now, let's try to split \"førstegangsintervju\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('første gang intervju', 19.370104879581454)"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_best_split5(\"førstegangsintervju\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Corner case 4: Eager splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('regn ing', 7.912333465235502)"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_best_split5(\"regning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Not all words should be split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Corner case 4: Solution - exception list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "DO_NOT_SPLIT = [\"regning\"]\n",
    "\n",
    "def find_best_split6(word):\n",
    "    # No split\n",
    "    max_value, best_split= word_value(word), word\n",
    "    if word in DO_NOT_SPLIT:\n",
    "        return best_split, max_value\n",
    "    \n",
    "    # Consider all splits\n",
    "    for i in range(min_word_length, len(word)-min_word_length+1):\n",
    "        sw1 = word[:i]\n",
    "        sw1_value = word_value(sw1)\n",
    "        \n",
    "        split_options = [i]\n",
    "        if word[i] in GLUE_LETTERS:\n",
    "            split_options.append(i+1)\n",
    "        if word[i-1] in 'bcdfghjklmnpqrstvxz' and word[i-1] == word[i-2]:\n",
    "            split_options.append(i-1)\n",
    "            \n",
    "        for j in split_options:\n",
    "            sw2, sw2_value = find_best_split6(word[j:])\n",
    "            value = sw1_value + sw2_value - SPLIT_PENALTY - (j!=i) * EDIT_PENALTY\n",
    "            if value > max_value:\n",
    "                max_value, best_split = value, sw1 + \" \" + sw2\n",
    "    \n",
    "    return best_split, max_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Now, let's try \"regning\" again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('regning', 5.910796644040527)"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_best_split6(\"regning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Let's try our algorithm on the example from earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Jeg har en reise regning', 'Jeg har en regning for en reise']"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = [\n",
    "    \"Jeg har en reiseregning\",\n",
    "    \"Jeg har en regning for en reise\"\n",
    "]\n",
    "\n",
    "clean_text = lambda text: \" \".join(find_best_split6(word)[0] for word in text.split())\n",
    " \n",
    "texts2 = [clean_text(text) for text in texts]\n",
    "texts2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>regning</th>\n",
       "      <th>reise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   regning  reise\n",
       "0        1      1\n",
       "1        1      1"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = CountVectorizer(stop_words=stopwords.words(\"norwegian\"))\n",
    "bow = vec.fit_transform(texts2)\n",
    "pd.DataFrame(bow.todense(), columns=vec.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Text similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow[0].dot(bow[1].T)[0,0] / bow.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src=\"https://media1.tenor.com/images/b5b525642d31fc32571618da55f973e5/tenor.gif?itemid=4786736\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Ending notes\n",
    "\n",
    "- A compound word splitter is not the only way to solve the problem of compound words\n",
    "- Another way to approach this problem is using character-level features instead of word-level features\n",
    "- The compound word splitter may not work properly if your corpora is too small, because you may not be able to get proper word counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Character-level features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>br</th>\n",
       "      <th>er</th>\n",
       "      <th>a e</th>\n",
       "      <th>ari</th>\n",
       "      <th>bra</th>\n",
       "      <th>er</th>\n",
       "      <th>ism</th>\n",
       "      <th>kar</th>\n",
       "      <th>ma</th>\n",
       "      <th>r b</th>\n",
       "      <th>ris</th>\n",
       "      <th>sma</th>\n",
       "      <th>vis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    br   er  a e  ari  bra  er   ism  kar  ma   r b  ris  sma  vis\n",
       "0    1    1    1    0    1    1    1    0    1    1    0    1    1\n",
       "1    1    1    1    1    1    1    1    1    1    1    1    1    0"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = [\n",
    "    \"Visma er bra\", \"Karisma er bra\"\n",
    "]\n",
    "vec = CountVectorizer(analyzer=\"char\", ngram_range=(3,3))\n",
    "bow = vec.fit_transform(texts)\n",
    "pd.DataFrame(bow.todense(), columns=vec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69230769230769229"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow[0].dot(bow[1].T)[0,0] / bow.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Character-level features cause other types of problems..."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
